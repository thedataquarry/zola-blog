<!doctype html><html lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content="light dark" name=color-scheme><title>Blazing fast async data loading in Meilisearch | The Data Quarry</title><meta content="Blazing fast async data loading in Meilisearch" property=og:title><meta content="Prashanth Rao" name=author><meta content=en_US property=og:locale><meta content="An ETL case study comparing sync and async data loading with Meilisearch using Python and Pydantic" name=description><meta content="An ETL case study comparing sync and async data loading with Meilisearch using Python and Pydantic" property=og:description><link href=https://thedataquarry.github.io/posts/meilisearch-async/ rel=canonical><meta content=https://thedataquarry.github.io/posts/meilisearch-async/ property=og:url><meta content="The Data Quarry" property=og:site_name><meta content=https://thedataquarry.github.io/img/dataquarry-banner.png property=og:image><meta content=article property=og:type><meta content=2023-07-28T00:00:00+00:00 property=article:published_time><meta " content=summary_large_image name=twitter:card><meta content=https://thedataquarry.github.io/img/dataquarry-banner.png property=twitter:image><meta content="Blazing fast async data loading in Meilisearch" property=twitter:title><meta content=@tech_optimist name=twitter:site><meta content="An ETL case study comparing sync and async data loading with Meilisearch using Python and Pydantic" name=description><title>Blazing fast async data loading in Meilisearch</title><link href=/img/favicon-32x32.png rel=icon sizes=32x32 type=image/png><link href=/img/favicon-16x16.png rel=icon sizes=16x16 type=image/png><link href=/img/apple-touch-icon.png rel=apple-touch-icon sizes=180x180><style>body{--primary-color:#376dd9;--primary-pale-color:#698bcf1c;--inline-code-color:#444;--text-color:#444;--text-pale-color:#545967;--bg-color:#fff;--highlight-mark-color:#5f75b045;--callout-note-color:#3e70d6;--callout-important-color:#7a46cd;--callout-warning-color:#d3822b;--callout-alert-color:#d43f3f;--callout-question-color:#3089b5;--callout-tip-color:#35a06b;--main-font:"IBMPlexSans",ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--code-font:"IBMPlexMono",ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;--homepage-max-width:750px;--main-max-width:750px;--avatar-size:175px;--paragraph-font-size:16px;--paragraph-line-height:1.5em;--aside-font-size:16px;--img-border-radius:4px;--inline-code-border-radius:2px}body.dark{--primary-color:#689afd;--primary-pale-color:#93acdd1c;--inline-code-color:#d2d2d2;--text-color:#ddd;--text-pale-color:#a0a0a0;--bg-color:#202124;--highlight-mark-color:#5f75b045;--callout-note-color:#698bcf;--callout-important-color:#9374c5;--callout-warning-color:#c99054;--callout-alert-color:#d35757;--callout-question-color:#5091b2;--callout-tip-color:#3ea06f}</style><link href=/main.css rel=stylesheet><script async data-website-id=01228822-c189-4b8a-93ba-733d045bf346 src=https://analytics.eu.umami.is/script.js></script><body class=post><script>if(localStorage.getItem('theme')=='dark'){document.body.classList.add('dark');const a=document.querySelector('link#hl');if(a)a.href='/hl-dark.css'}</script><header class=blur><div id=header-wrapper><nav><a href=/>The Data Quarry</a><button aria-label="toggle expand" class=separator id=toggler>::</button><span class="wrap left fold">{</span><a href=/posts>blog</a><span class="wrap-separator fold">,</span><a class=fold href=/talks>talks</a><span class="wrap-separator fold">,</span><a class=fold href=/projects>projects</a><span class="wrap right fold">} ;</span></nav><div id=btns><a rel="noreferrer noopener" aria-label=GitHub href=https://github.com/prrao87 target=_blank> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12" fill=currentColor></path></svg> </a><a rel="noreferrer noopener" aria-label=Twitter href=https://twitter.com/tech_optimist target=_blank> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><title>Twitter</title><path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z" fill=currentColor></path></svg> </a><a rel="noreferrer noopener" aria-label=LinkedIn href=https://www.linkedin.com/in/prrao87 target=_blank> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z" fill=currentColor></path></svg> </a><a aria-label="Buy me a coffee" rel="noreferrer noopener" href=https://www.buymeacoffee.com/prrao87 target=_blank> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><title>Buy Me A Coffee</title><path d="M20.216 6.415l-.132-.666c-.119-.598-.388-1.163-1.001-1.379-.197-.069-.42-.098-.57-.241-.152-.143-.196-.366-.231-.572-.065-.378-.125-.756-.192-1.133-.057-.325-.102-.69-.25-.987-.195-.4-.597-.634-.996-.788a5.723 5.723 0 00-.626-.194c-1-.263-2.05-.36-3.077-.416a25.834 25.834 0 00-3.7.062c-.915.083-1.88.184-2.75.5-.318.116-.646.256-.888.501-.297.302-.393.77-.177 1.146.154.267.415.456.692.58.36.162.737.284 1.123.366 1.075.238 2.189.331 3.287.37 1.218.05 2.437.01 3.65-.118.299-.033.598-.073.896-.119.352-.054.578-.513.474-.834-.124-.383-.457-.531-.834-.473-.466.074-.96.108-1.382.146-1.177.08-2.358.082-3.536.006a22.228 22.228 0 01-1.157-.107c-.086-.01-.18-.025-.258-.036-.243-.036-.484-.08-.724-.13-.111-.027-.111-.185 0-.212h.005c.277-.06.557-.108.838-.147h.002c.131-.009.263-.032.394-.048a25.076 25.076 0 013.426-.12c.674.019 1.347.067 2.017.144l.228.031c.267.04.533.088.798.145.392.085.895.113 1.07.542.055.137.08.288.111.431l.319 1.484a.237.237 0 01-.199.284h-.003c-.037.006-.075.01-.112.015a36.704 36.704 0 01-4.743.295 37.059 37.059 0 01-4.699-.304c-.14-.017-.293-.042-.417-.06-.326-.048-.649-.108-.973-.161-.393-.065-.768-.032-1.123.161-.29.16-.527.404-.675.701-.154.316-.199.66-.267 1-.069.34-.176.707-.135 1.056.087.753.613 1.365 1.37 1.502a39.69 39.69 0 0011.343.376.483.483 0 01.535.53l-.071.697-1.018 9.907c-.041.41-.047.832-.125 1.237-.122.637-.553 1.028-1.182 1.171-.577.131-1.165.2-1.756.205-.656.004-1.31-.025-1.966-.022-.699.004-1.556-.06-2.095-.58-.475-.458-.54-1.174-.605-1.793l-.731-7.013-.322-3.094c-.037-.351-.286-.695-.678-.678-.336.015-.718.3-.678.679l.228 2.185.949 9.112c.147 1.344 1.174 2.068 2.446 2.272.742.12 1.503.144 2.257.156.966.016 1.942.053 2.892-.122 1.408-.258 2.465-1.198 2.616-2.657.34-3.332.683-6.663 1.024-9.995l.215-2.087a.484.484 0 01.39-.426c.402-.078.787-.212 1.074-.518.455-.488.546-1.124.385-1.766zm-1.478.772c-.145.137-.363.201-.578.233-2.416.359-4.866.54-7.308.46-1.748-.06-3.477-.254-5.207-.498-.17-.024-.353-.055-.47-.18-.22-.236-.111-.71-.054-.995.052-.26.152-.609.463-.646.484-.057 1.046.148 1.526.22.577.088 1.156.159 1.737.212 2.48.226 5.002.19 7.472-.14.45-.06.899-.13 1.345-.21.399-.072.84-.206 1.08.206.166.281.188.657.162.974a.544.544 0 01-.169.364zm-6.159 3.9c-.862.37-1.84.788-3.109.788a5.884 5.884 0 01-1.569-.217l.877 9.004c.065.78.717 1.38 1.5 1.38 0 0 1.243.065 1.658.065.447 0 1.786-.065 1.786-.065.783 0 1.434-.6 1.499-1.38l.94-9.95a3.996 3.996 0 00-1.322-.238c-.826 0-1.491.284-2.26.613z" fill=currentColor></path></svg> </a><button aria-label="theme switch" data-moon-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24"><path d="M10 7C10 10.866 13.134 14 17 14C18.9584 14 20.729 13.1957 21.9995 11.8995C22 11.933 22 11.9665 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12C2 6.47715 6.47715 2 12 2C12.0335 2 12.067 2 12.1005 2.00049C10.8043 3.27098 10 5.04157 10 7ZM4 12C4 16.4183 7.58172 20 12 20C15.0583 20 17.7158 18.2839 19.062 15.7621C18.3945 15.9187 17.7035 16 17 16C12.0294 16 8 11.9706 8 7C8 6.29648 8.08133 5.60547 8.2379 4.938C5.71611 6.28423 4 8.9417 4 12Z" fill="currentColor"></path></svg>' data-sun-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24"><path d="M12 18C8.68629 18 6 15.3137 6 12C6 8.68629 8.68629 6 12 6C15.3137 6 18 8.68629 18 12C18 15.3137 15.3137 18 12 18ZM12 16C14.2091 16 16 14.2091 16 12C16 9.79086 14.2091 8 12 8C9.79086 8 8 9.79086 8 12C8 14.2091 9.79086 16 12 16ZM11 1H13V4H11V1ZM11 20H13V23H11V20ZM3.51472 4.92893L4.92893 3.51472L7.05025 5.63604L5.63604 7.05025L3.51472 4.92893ZM16.9497 18.364L18.364 16.9497L20.4853 19.0711L19.0711 20.4853L16.9497 18.364ZM19.0711 3.51472L20.4853 4.92893L18.364 7.05025L16.9497 5.63604L19.0711 3.51472ZM5.63604 16.9497L7.05025 18.364L4.92893 20.4853L3.51472 19.0711L5.63604 16.9497ZM23 11V13H20V11H23ZM4 11V13H1V11H4Z" fill="currentColor"></path></svg>' id=theme-toggle><svg viewbox="0 0 24 24" height=24 width=24 xmlns=http://www.w3.org/2000/svg><path d="M10 7C10 10.866 13.134 14 17 14C18.9584 14 20.729 13.1957 21.9995 11.8995C22 11.933 22 11.9665 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12C2 6.47715 6.47715 2 12 2C12.0335 2 12.067 2 12.1005 2.00049C10.8043 3.27098 10 5.04157 10 7ZM4 12C4 16.4183 7.58172 20 12 20C15.0583 20 17.7158 18.2839 19.062 15.7621C18.3945 15.9187 17.7035 16 17 16C12.0294 16 8 11.9706 8 7C8 6.29648 8.08133 5.60547 8.2379 4.938C5.71611 6.28423 4 8.9417 4 12Z" fill=currentColor></path></svg></button><button aria-label="table of content" id=toc-toggle><svg viewbox="0 0 24 24" height=24 width=24 xmlns=http://www.w3.org/2000/svg><path d="M3 4H21V6H3V4ZM3 11H15V13H3V11ZM3 18H21V20H3V18Z" fill=currentColor></path></svg></button></div></div></header><div id=wrapper><div id=blank></div><aside class=blur><nav><ul><li><a class=h2 href=#background>Background</a> <ul><li><a class=h3 href=#sync-multi-threaded-and-async>Sync, multi-threaded and async</a><li><a class=h3 href=#the-data>The data</a><li><a class=h3 href=#etl-steps>ETL steps</a><li><a class=h3 href=#meilisearch-settings>Meilisearch settings</a><li><a class=h3 href=#meilisearch-task-queue>Meilisearch task queue</a></ul><li><a class=h2 href=#case-1-sync>Case 1: Sync</a><li><a class=h2 href=#case-2-async>Case 2: Async</a><li><a class=h2 href=#results-discussion>Results & discussion</a> <ul><li><a class=h3 href=#search-results-on-the-front-end>Search results on the front end</a></ul><li><a class=h2 href=#conclusions>Conclusions</a> <ul><li><a class=h3 href=#when-is-meilisearch-a-great-fit>When is Meilisearch a great fit?</a><li><a class=h3 href=#limitations-of-meilisearch>Limitations of Meilisearch</a></ul><li><a class=h2 href=#code-acknowledgements>Code & acknowledgements</a></ul></nav><button aria-label="back to top" id=back-to-top><svg viewbox="0 0 24 24" height=24 width=24 xmlns=http://www.w3.org/2000/svg><path d="M11.9997 10.8284L7.04996 15.7782L5.63574 14.364L11.9997 8L18.3637 14.364L16.9495 15.7782L11.9997 10.8284Z" fill=currentColor></path></svg></button></aside><main><div><div data-check-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24"><path d="M10.0007 15.1709L19.1931 5.97852L20.6073 7.39273L10.0007 17.9993L3.63672 11.6354L5.05093 10.2212L10.0007 15.1709Z" fill="currentColor"></path></svg>' data-copy-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24"><path d="M6.9998 6V3C6.9998 2.44772 7.44752 2 7.9998 2H19.9998C20.5521 2 20.9998 2.44772 20.9998 3V17C20.9998 17.5523 20.5521 18 19.9998 18H16.9998V20.9991C16.9998 21.5519 16.5499 22 15.993 22H4.00666C3.45059 22 3 21.5554 3 20.9991L3.0026 7.00087C3.0027 6.44811 3.45264 6 4.00942 6H6.9998ZM5.00242 8L5.00019 20H14.9998V8H5.00242ZM8.9998 6H16.9998V16H18.9998V4H8.9998V6Z" fill="currentColor"></path></svg>' id=copy-cfg style=display:none></div><article data-backlink-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path d="M9.41421 8L18.0208 16.6066L16.6066 18.0208L8 9.41421V17H6V6H17V8H9.41421Z" fill="currentColor"></path></svg>' class=prose><h1>Blazing fast async data loading in Meilisearch</h1><div id=post-info><div id=date><span id=publish>2023-07-28</span><span>Updated: <span id=updated>2023-11-29</span></span></div><div id=tags><a href=https://thedataquarry.github.io/tags/meilisearch><span>#</span>meilisearch</a><a href=https://thedataquarry.github.io/tags/async><span>#</span>async</a><a href=https://thedataquarry.github.io/tags/pydantic><span>#</span>pydantic</a></div></div><h2 id=background>Background<a aria-label="Anchor link for: background" class=zola-anchor href=#background>#</a></h2><p>If you‚Äôve ever visited the <a rel="nofollow noreferrer" href=https://huggingface.co/models>Hugging Face model hub</a>, you‚Äôve probably searched for your favourite NLP models by typing in their names, in part or in full. And, very quickly after you stop typing, you obtain a rather relevant set of results, in a matter of milliseconds. How is that possible? While it may seem like the ‚Äòsearch-as-you-type‚Äô functionality requires a lot of computing power, with the right underlying search index and database in place, it‚Äôs actually <em>not</em> that expensive. Under the hood, these search functions are powered by Meilisearch, an open-source, lightning fast ‚ö°Ô∏è, typo-tolerant search engine and database built in Rust ü¶Ä.<p>In this article, I‚Äôll do a case study comparing an async ETL data loading workflow vs. the commonly used sync workflow used in most situations. I‚Äôll also highlight how a modern, lightweight database built in Rust can be used in conjunction with a well-designed async Python client<sup class=footnote-reference><a href=#1>1</a></sup> to <em>very</em> rapidly load data and index it under the hood.<h3 id=sync-multi-threaded-and-async>Sync, multi-threaded and async<a aria-label="Anchor link for: sync-multi-threaded-and-async" class=zola-anchor href=#sync-multi-threaded-and-async>#</a></h3><p>Before going into the code, let‚Äôs review the difference between sync, async and multi-threaded programs.<ul><li>In a synchronous program, the program will wait for a task to complete before moving on to the next task. In other words, each task ‚Äúblocks‚Äù the executing thread until it is finished.<li>In a multi-threaded program, the program will spawn a new thread for each task, and the threads will process each task concurrently<li>In an asynchronous program, the <em>same</em> thread that starts a task will then move on to the next task while the first task is running. The program will then return to the first task when it is finished with the next one. In other words, each task is ‚Äúnon-blocking‚Äù, because it yields control to the thread before it‚Äôs finished.</ul><p>The following diagram visualizes this distinction ‚Äì note how even though the sync and async cases both use single threads (unlike the multi-threaded case), the async case is able to process more tasks in the same amount of time because it doesn‚Äôt block the thread while waiting for a task to finish. The mechanism through which the async code achieves this is called the <em>event loop</em>, whose description is out of the scope of this post, but it‚Äôs highly recommended to read up on event loops in more detail if you‚Äôre interested in understanding async programming.<figure><img loading=lazy src=meilisearch-async-vs-multithread.png></figure><p>In most cases, async outperforms multi-threaded, because in spawning multiple threads on the same core, we introduce additional overhead in managing the communication between the threads. The async approach most effectively utilizes the full power of a single thread in a non-blocking manner. However, it also makes the program harder to reason about, due to potential race-conditions<sup class=footnote-reference><a href=#2>2</a></sup> and deadlocks, so it must be used with care.<p>It is for this reason that most folks handling the lower-level async utilities in Python are library developers, who do the hard work of making sure that the higher-level async libraries are safe to use for end users like us.üòÖ<blockquote class="callout warning"><div class=icon><svg viewbox="0 0 24 24" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M12.865 3.00017L22.3912 19.5002C22.6674 19.9785 22.5035 20.5901 22.0252 20.8662C21.8732 20.954 21.7008 21.0002 21.5252 21.0002H2.47266C1.92037 21.0002 1.47266 20.5525 1.47266 20.0002C1.47266 19.8246 1.51886 19.6522 1.60663 19.5002L11.1329 3.00017C11.4091 2.52187 12.0206 2.358 12.4989 2.63414C12.651 2.72191 12.7772 2.84815 12.865 3.00017ZM4.20471 19.0002H19.7932L11.9989 5.50017L4.20471 19.0002ZM10.9989 16.0002H12.9989V18.0002H10.9989V16.0002ZM10.9989 9.00017H12.9989V14.0002H10.9989V9.00017Z" fill=currentColor></path></svg></div><div class=content><p>The case study in this post shows ETL code that is either sync or async, but not multi-threaded. The async version uses the <code>meilisearch-python-sdk</code> <a rel="nofollow noreferrer" href=https://github.com/sanders41/meilisearch-python-sdk>client</a>, maintained by Paul Sanders.</div></blockquote><h3 id=the-data>The data<a aria-label="Anchor link for: the-data" class=zola-anchor href=#the-data>#</a></h3><p>The dataset being loaded in this case study consists of 130k wine reviews from the Wine Enthusiast magazine, including the variety, location, winery, price, description, and some other metadata for each wine. Refer to the <a rel="nofollow noreferrer" href=https://www.kaggle.com/datasets/zynicide/wine-reviews>Kaggle source</a> for more detailed information on the data and how it was scraped.<p>An example JSON record is shown below.<pre class=language-json data-lang=json style=background:#2e3440;color:#d8dee9><code class=language-json data-lang=json><span>{
</span><span>    </span><span style=color:#a3be8c>"points"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"90"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"title"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Castello San Donato in Perano 2009 Riserva  (Chianti Classico)"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"description"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Made from a blend of 85% Sangiovese and 15% Merlot, this ripe wine delivers soft plum, black currants, clove and cracked pepper sensations accented with coffee and espresso notes. A backbone of firm tannins give structure. Drink now through 2019."</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"taster_name"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Kerin O'Keefe"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"taster_twitter_handle"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"@kerinokeefe"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"price"</span><span style=color:#eceff4>: </span><span style=color:#b48ead>30</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"designation"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Riserva"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"variety"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Red Blend"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"region_1"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Chianti Classico"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"region_2"</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>null</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"province"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Tuscany"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"country"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Italy"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"winery"</span><span style=color:#eceff4>: </span><span style=color:#a3be8c>"Castello San Donato in Perano"</span><span style=color:#eceff4>,
</span><span>    </span><span style=color:#a3be8c>"id"</span><span style=color:#eceff4>: </span><span style=color:#b48ead>40825
</span><span>}
</span></code></pre><p>To test the performance of sync vs. async data loading in Meilisearch, we will run a benchmark where the same set of 130k records is loaded in a loop, either 1, 10 or 100 times. This will allow us to see how the performance of the sync and async versions scales with the size of the data.<h3 id=etl-steps>ETL steps<a aria-label="Anchor link for: etl-steps" class=zola-anchor href=#etl-steps>#</a></h3><p>The workflow described in this post consists of the following steps:<ul><li>Read in a settings config file that describes the indexing settings for Meilisearch<li>Read the raw data as a list of records (i.e., JSON blobs)<li>Validate the data using Pydantic ‚Äì in this post, we use Pydantic v2, which is <a href=../why-pydantic-v2-matters/>5-10x faster than v1</a>.<li>Send a list of validated records to Meilisearch for indexing <ul><li>Use either the sync or async Python client for Meilisearch, whose results will be compared</ul><li>Verify that the index works as intended by testing search-as-you-type queries</ul><h3 id=meilisearch-settings>Meilisearch settings<a aria-label="Anchor link for: meilisearch-settings" class=zola-anchor href=#meilisearch-settings>#</a></h3><p>A key step prior to loading the data into Meilisearch is to define the index settings. This is critical to ensure that the search performance is as expected, and that the index building time is reasonable regardless of the size of the data. The settings configuration is stored as a JSON file, and is read in as a Python dictionary. Some of the important attributes to set are:<ul><li><strong>Searchable attributes</strong>: Even if we have a JSON blob with a lot of fields, it makes sense to ensure that only the fields that will be searched, should have their values indexed<li><strong>Filterable and sortable attributes</strong>: Depending on the user‚Äôs needs during query time, certain fields should be marked as filterable, and others as sortable. In the wine reviews example here, <code>price</code> and <code>points</code> should be sortable, while <code>country</code> and <code>variety</code> should be filterable to offer the most relevant search experience.<li><strong>Ranking rules</strong>: Meilisearch defines rules to decide the relevance of search result, and certain parameters can be prioritized prior to indexing to offer a better search experience: <ul><li>Words: Results are sorted by decreasing number of matched query terms<li>Typo: Results are sorted by increasing number of typos<li>Proximity: Results are sorted by increasing distance between matched query terms<li>Attribute: Results are sorted in the order of a specified attribute list (for example, <code>variety</code> matters more than <code>province</code>)<li>Sort: Results are sorted according to parameters decided at query time (for example, <code>price</code> or <code>points</code>)<li>Exactness: Results are sorted by the similarity between matched terms and query terms<li>Custom rules: Sorts results in ascending or descending order for a given attribute</ul></ul><p>A much more exhaustive guide to optimizing Meilisearch settings to speed up indexing while also ensuring a relevant search is described in their blog<sup class=footnote-reference><a href=#3>3</a></sup>. If you‚Äôre looking to index large documents with long-form text, it‚Äôs highly recommended to read through this guide in detail.<h3 id=meilisearch-task-queue>Meilisearch task queue<a aria-label="Anchor link for: meilisearch-task-queue" class=zola-anchor href=#meilisearch-task-queue>#</a></h3><p>Just like the data is loaded asynchronously, Meilisearch itself performs tasks asynchronously under the hood<sup class=footnote-reference><a href=#8>4</a></sup>. The data that‚Äôs loaded into Meilisearch is not immediately available, because it‚Äôs being indexed in the background. In creating the index, Meilisearch creates roughly 20 data structures, with each batch processed concurrently in the order they came in.<p>A caveat is, however, as more and more data gets ingested (for really huge datasets numbering in the hundreds of millions of records), the indexing takes progressively longer, especially if long-form text fields are indexed. In any case, searching through these large dumps of data isn‚Äôt the primary use case for Meilisearch, as described in their blog<sup class=footnote-reference><a href=#4>5</a></sup>. Before indexing any data in Meilisearch, it‚Äôs always a good idea to understand what indexing involves, and to read the docs to optimize the indexing process. üòÖ<h2 id=case-1-sync>Case 1: Sync<a aria-label="Anchor link for: case-1-sync" class=zola-anchor href=#case-1-sync>#</a></h2><p>The synchronous ETL case uses the official Meilisearch Python client, in conjunction with Pydantic, to ensure that the data is of the right type and quality prior to loading into Meilisearch. I won‚Äôt go into the details of the Pydantic schema here, as that has been covered in detail in my <a href=../neo4j-python-1/>earlier post on loading data into Neo4j</a>. In a nutshell, the JSON data is read in, and validated against a Pydantic schema. The validated data is then sent to Meilisearch for indexing.<p>The <code>main</code> function for sync ETL is shown below. Note that Meilisearch requires that every record being indexed has a unique identifier which serves as the primary key. In this case, the integer <code>id</code> field is used as the primary key. The <code>Timer</code> context manager from the <code>codetiming</code> package is used to time the indexing process.<pre class=language-python data-lang=python style=background:#2e3440;color:#d8dee9><code class=language-python data-lang=python><span style=color:#81a1c1>import </span><span>srsly
</span><span style=color:#81a1c1>from </span><span>codetiming </span><span style=color:#81a1c1>import </span><span>codetiming
</span><span style=color:#81a1c1>from </span><span>meilisearch </span><span style=color:#81a1c1>import </span><span>Client
</span><span style=color:#81a1c1>from </span><span>meilisearch</span><span style=color:#81a1c1>.</span><span>index </span><span style=color:#81a1c1>import </span><span>Index
</span><span style=color:#81a1c1>from </span><span>tqdm </span><span style=color:#81a1c1>import </span><span>tqdm
</span><span>
</span><span>
</span><span style=color:#81a1c1>def </span><span style=color:#88c0d0>get_meili_settings</span><span>(filename</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>str</span><span>) </span><span style=color:#eceff4>-> </span><span style=color:#81a1c1>dict</span><span>[</span><span style=color:#81a1c1>str</span><span>, Any]:
</span><span>    settings </span><span style=color:#81a1c1>= dict</span><span>(srsly</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>read_json</span><span>(filename))
</span><span>    </span><span style=color:#81a1c1>return </span><span>settings
</span><span>
</span><span>
</span><span style=color:#81a1c1>def </span><span style=color:#88c0d0>update_documents</span><span>(filepath</span><span style=color:#eceff4>: </span><span>Path</span><span style=color:#eceff4>, </span><span>index</span><span style=color:#eceff4>: </span><span>Index</span><span style=color:#eceff4>, </span><span>primary_key</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>str</span><span style=color:#eceff4>, </span><span>batch_size</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>int</span><span>):
</span><span>    data </span><span style=color:#81a1c1>= list</span><span>(</span><span style=color:#88c0d0>get_json_data</span><span>(filepath))
</span><span>    </span><span style=color:#81a1c1>if LIMIT > </span><span style=color:#b48ead>0</span><span>:
</span><span>        data </span><span style=color:#81a1c1>= </span><span>data[</span><span style=color:#eceff4>:</span><span style=color:#81a1c1>LIMIT</span><span>]
</span><span>    validated_data </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>validate</span><span>(data)
</span><span>    index</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>update_documents_in_batches</span><span>(
</span><span>        validated_data</span><span style=color:#eceff4>,
</span><span>        batch_size</span><span style=color:#81a1c1>=</span><span>batch_size</span><span style=color:#eceff4>,
</span><span>        primary_key</span><span style=color:#81a1c1>=</span><span>primary_key</span><span style=color:#eceff4>,
</span><span>    )
</span><span>
</span><span>
</span><span style=color:#81a1c1>def </span><span style=color:#88c0d0>main</span><span>(data_files</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>list</span><span>[Path]) </span><span style=color:#eceff4>-> </span><span style=color:#81a1c1>None</span><span>:
</span><span>    meili_settings </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>get_meili_settings</span><span>(filename</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"settings/settings.json"</span><span>)
</span><span>    config </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>Settings</span><span>()
</span><span>    </span><span style=color:#81a1c1>URI = f</span><span style=color:#a3be8c>"http://</span><span>{config</span><span style=color:#81a1c1>.</span><span>meili_url}</span><span style=color:#a3be8c>:</span><span>{config</span><span style=color:#81a1c1>.</span><span>meili_port}</span><span style=color:#a3be8c>"
</span><span>    </span><span style=color:#81a1c1>MASTER_KEY = </span><span>config</span><span style=color:#81a1c1>.</span><span>meili_master_key
</span><span>    index_name </span><span style=color:#81a1c1>= </span><span style=color:#a3be8c>"wines"
</span><span>    primary_key </span><span style=color:#81a1c1>= </span><span style=color:#a3be8c>"id"
</span><span>
</span><span>    client </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>Client</span><span>(</span><span style=color:#81a1c1>URI</span><span style=color:#eceff4>, </span><span style=color:#81a1c1>MASTER_KEY</span><span>)
</span><span>    </span><span style=color:#81a1c1>with </span><span style=color:#88c0d0>Timer</span><span>(name</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"Bulk Index"</span><span style=color:#eceff4>, </span><span>text</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"Bulk index took </span><span style=color:#ebcb8b>{</span><span>:.4f</span><span style=color:#ebcb8b>}</span><span style=color:#a3be8c> seconds"</span><span>):
</span><span>        </span><span style=color:#616e88># Create index
</span><span>        index </span><span style=color:#81a1c1>= </span><span>client</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>index</span><span>(index_name)
</span><span>        </span><span style=color:#616e88># Update settings
</span><span>        client</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>index</span><span>(index_name)</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>update_settings</span><span>(meili_settings)
</span><span>        </span><span style=font-style:italic;color:#88c0d0>print</span><span>(</span><span style=color:#a3be8c>"Finished updating database index settings"</span><span>)
</span><span>        </span><span style=color:#81a1c1>try</span><span>:
</span><span>            </span><span style=color:#616e88># In a real case we'd be iterating through a list of files
</span><span>            </span><span style=color:#616e88># For this example, it's just looping through the same file N times
</span><span>            </span><span style=color:#81a1c1>for </span><span>filepath </span><span style=color:#81a1c1>in </span><span style=color:#88c0d0>tqdm</span><span>(data_files):
</span><span>                </span><span style=color:#616e88># Update index
</span><span>                </span><span style=color:#88c0d0>update_documents</span><span>(filepath</span><span style=color:#eceff4>, </span><span>index</span><span style=color:#eceff4>, </span><span>primary_key</span><span style=color:#81a1c1>=</span><span>primary_key</span><span style=color:#eceff4>, </span><span>batch_size</span><span style=color:#81a1c1>=</span><span style=color:#b48ead>10000</span><span>)
</span><span>        </span><span style=color:#81a1c1>except </span><span style=color:#8fbcbb>Exception </span><span style=color:#81a1c1>as </span><span>e:
</span><span>            </span><span style=font-style:italic;color:#88c0d0>print</span><span>(</span><span style=color:#81a1c1>f</span><span style=color:#a3be8c>"</span><span>{e}</span><span style=color:#a3be8c>: Error while indexing to db"</span><span>)
</span></code></pre><p>The <code>index.update_documents_in_batches()</code> method available in the Meilisearch client is used, so that we don‚Äôt have to batch the data in Python ‚Äì passing the entire list of records to Meilisearch and letting it handle the batching is much more efficient, as all the underlying operations are done in Rust. The <code>batch_size</code> parameter for this method is set to 10k. Running the bulk indexing script on ~130k, 1.3M and 13M records respectively, produce the following timing numbers.<div class=codeblock-with-filename><div class=filename>bash</div><pre class=language-bash data-lang=bash style=background:#2e3440;color:#d8dee9><code class=language-bash data-lang=bash><span style=color:#88c0d0>$</span><span> python bulk_index_sync.py -b 1
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>1/1 </span><span style=color:#81a1c1>[</span><span>00:01&LT00:00,  1.56s/it</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Bulk</span><span> index took 2.2505 seconds
</span><span>
</span><span style=color:#88c0d0>$</span><span> python bulk_index_sync.py -b 10
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>10/10 </span><span style=color:#81a1c1>[</span><span>00:15&LT00:00,  1.54s/it</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Bulk</span><span> index took 16.1129 seconds
</span><span>
</span><span style=color:#88c0d0>$</span><span> python bulk_index_sync.py -b 100
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>100/100 </span><span style=color:#81a1c1>[</span><span>02:43&LT00:00,  1.64s/it</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Bulk</span><span> index took 164.3521 seconds
</span></code></pre></div><h2 id=case-2-async>Case 2: Async<a aria-label="Anchor link for: case-2-async" class=zola-anchor href=#case-2-async>#</a></h2><p>The async version uses the <code>meilisearch-python-sdk</code> async client<sup class=footnote-reference><a href=#1>1</a></sup>, whose API is remarkably similar to the official sync client from Meilisearch.<pre class=language-python data-lang=python style=background:#2e3440;color:#d8dee9><code class=language-python data-lang=python><span style=color:#81a1c1>import </span><span>srsly
</span><span style=color:#81a1c1>from </span><span>codetiming </span><span style=color:#81a1c1>import </span><span>codetiming
</span><span style=color:#81a1c1>from </span><span>meilisearch_python_async </span><span style=color:#81a1c1>import </span><span>Client
</span><span style=color:#81a1c1>from </span><span>meilisearch_python_async</span><span style=color:#81a1c1>.</span><span>index </span><span style=color:#81a1c1>import </span><span>Index
</span><span style=color:#81a1c1>from </span><span>meilisearch_python_async</span><span style=color:#81a1c1>.</span><span>models</span><span style=color:#81a1c1>.</span><span>settings </span><span style=color:#81a1c1>import </span><span>MeilisearchSettings
</span><span style=color:#81a1c1>from </span><span>tqdm</span><span style=color:#81a1c1>.</span><span>asyncio </span><span style=color:#81a1c1>import </span><span>tqdm_asyncio
</span><span>
</span><span>
</span><span style=color:#81a1c1>def </span><span style=color:#88c0d0>get_meili_settings</span><span>(filename</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>str</span><span>) </span><span style=color:#eceff4>-> </span><span>MeilisearchSettings:
</span><span>    settings </span><span style=color:#81a1c1>= dict</span><span>(srsly</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>read_json</span><span>(filename))
</span><span>    </span><span style=color:#616e88># Convert to MeilisearchSettings pydantic model object
</span><span>    settings </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>MeilisearchSettings</span><span>(</span><span style=color:#81a1c1>**</span><span>settings)
</span><span>    </span><span style=color:#81a1c1>return </span><span>settings
</span><span>
</span><span>
</span><span style=color:#81a1c1>async def </span><span style=color:#88c0d0>update_documents</span><span>(filepath</span><span style=color:#eceff4>: </span><span>Path</span><span style=color:#eceff4>, </span><span>index</span><span style=color:#eceff4>: </span><span>Index</span><span style=color:#eceff4>, </span><span>primary_key</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>str</span><span style=color:#eceff4>, </span><span>batch_size</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>int</span><span>):
</span><span>    data </span><span style=color:#81a1c1>= list</span><span>(</span><span style=color:#88c0d0>get_json_data</span><span>(filepath))
</span><span>    validated_data </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>validate</span><span>(data)
</span><span>    </span><span style=color:#81a1c1>await </span><span>index</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>update_documents_in_batches</span><span>(
</span><span>        validated_data</span><span style=color:#eceff4>,
</span><span>        batch_size</span><span style=color:#81a1c1>=</span><span>batch_size</span><span style=color:#eceff4>,
</span><span>        primary_key</span><span style=color:#81a1c1>=</span><span>primary_key</span><span style=color:#eceff4>,
</span><span>    )
</span><span>
</span><span>
</span><span style=color:#81a1c1>async def </span><span style=color:#88c0d0>main</span><span>(data_files</span><span style=color:#eceff4>: </span><span style=color:#81a1c1>list</span><span>[Path]) </span><span style=color:#eceff4>-> </span><span style=color:#81a1c1>None</span><span>:
</span><span>    meili_settings </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>get_meili_settings</span><span>(filename</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"settings/settings.json"</span><span>)
</span><span>    config </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>Settings</span><span>()
</span><span>    </span><span style=color:#81a1c1>URI = f</span><span style=color:#a3be8c>"http://</span><span>{config</span><span style=color:#81a1c1>.</span><span>meili_url}</span><span style=color:#a3be8c>:</span><span>{config</span><span style=color:#81a1c1>.</span><span>meili_port}</span><span style=color:#a3be8c>"
</span><span>    </span><span style=color:#81a1c1>MASTER_KEY = </span><span>config</span><span style=color:#81a1c1>.</span><span>meili_master_key
</span><span>    index_name </span><span style=color:#81a1c1>= </span><span style=color:#a3be8c>"wines"
</span><span>    primary_key </span><span style=color:#81a1c1>= </span><span style=color:#a3be8c>"id"
</span><span>    </span><span style=color:#81a1c1>async with </span><span style=color:#88c0d0>Client</span><span>(</span><span style=color:#81a1c1>URI</span><span style=color:#eceff4>, </span><span style=color:#81a1c1>MASTER_KEY</span><span>) </span><span style=color:#81a1c1>as </span><span>client:
</span><span>        </span><span style=color:#81a1c1>with </span><span style=color:#88c0d0>Timer</span><span>(name</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"Bulk Index"</span><span style=color:#eceff4>, </span><span>text</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"Bulk index took </span><span style=color:#ebcb8b>{</span><span>:.4f</span><span style=color:#ebcb8b>}</span><span style=color:#a3be8c> seconds"</span><span>):
</span><span>            </span><span style=color:#616e88># Create index
</span><span>            index </span><span style=color:#81a1c1>= </span><span>client</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>index</span><span>(index_name)
</span><span>            </span><span style=color:#616e88># Update settings
</span><span>            </span><span style=color:#81a1c1>await </span><span>client</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>index</span><span>(index_name)</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>update_settings</span><span>(meili_settings)
</span><span>            </span><span style=font-style:italic;color:#88c0d0>print</span><span>(</span><span style=color:#a3be8c>"Finished updating database index settings"</span><span>)
</span><span>            file_chunks </span><span style=color:#81a1c1>= </span><span style=color:#88c0d0>chunk_files</span><span>(data_files</span><span style=color:#eceff4>, </span><span>file_chunksize</span><span style=color:#81a1c1>=</span><span style=color:#b48ead>5</span><span>)
</span><span>            </span><span style=color:#81a1c1>for </span><span>chunk </span><span style=color:#81a1c1>in </span><span style=color:#88c0d0>tqdm</span><span>(
</span><span>                file_chunks</span><span style=color:#eceff4>, </span><span>desc</span><span style=color:#81a1c1>=</span><span style=color:#a3be8c>"Handling file chunks"</span><span style=color:#eceff4>, </span><span>total</span><span style=color:#81a1c1>=</span><span style=font-style:italic;color:#88c0d0>len</span><span>(data_files) </span><span style=color:#81a1c1>// </span><span style=color:#b48ead>5
</span><span>            ):
</span><span>                </span><span style=color:#81a1c1>try</span><span>:
</span><span>                    tasks </span><span style=color:#81a1c1>= </span><span>[
</span><span>                        </span><span style=color:#616e88># Update index
</span><span>                        </span><span style=color:#88c0d0>update_documents</span><span>(
</span><span>                            filepath</span><span style=color:#eceff4>,
</span><span>                            index</span><span style=color:#eceff4>,
</span><span>                            primary_key</span><span style=color:#81a1c1>=</span><span>primary_key</span><span style=color:#eceff4>,
</span><span>                            batch_size</span><span style=color:#81a1c1>=</span><span style=color:#b48ead>10000</span><span style=color:#eceff4>,
</span><span>                        )
</span><span>                        </span><span style=color:#616e88># In a real case we'd be iterating through a list of files
</span><span>                        </span><span style=color:#616e88># For this example, it's just looping through the same file N times
</span><span>                        </span><span style=color:#81a1c1>for </span><span>filepath </span><span style=color:#81a1c1>in </span><span>chunk
</span><span>                    ]
</span><span>                    </span><span style=color:#81a1c1>await </span><span>tqdm_asyncio</span><span style=color:#81a1c1>.</span><span style=color:#88c0d0>gather</span><span>(</span><span style=color:#81a1c1>*</span><span>tasks)
</span><span>                </span><span style=color:#81a1c1>except </span><span style=color:#8fbcbb>Exception </span><span style=color:#81a1c1>as </span><span>e:
</span><span>                    </span><span style=font-style:italic;color:#88c0d0>print</span><span>(</span><span style=color:#81a1c1>f</span><span style=color:#a3be8c>"</span><span>{e}</span><span style=color:#a3be8c>: Error while indexing to db"</span><span>)
</span><span>        </span><span style=font-style:italic;color:#88c0d0>print</span><span>(</span><span style=color:#81a1c1>f</span><span style=color:#a3be8c>"Finished running benchmarks"</span><span>)
</span></code></pre><p>The key difference in the code in the async version is how we gather tasks. Each batch of records that needs to be loaded is stored in a list, and is then awaited via <code>asyncio.gather(*tasks)</code>. To observe the progress, we use the <code>tqdm_asyncio.gather(*tasks)</code> method that wraps a progress bar on top of the running <code>asyncio</code> event loop. Running the bulk indexing script on ~130k, 1.3M and 13M records respectively, produce the following timing numbers.<div class=codeblock-with-filename><div class=filename>bash</div><pre class=language-bash data-lang=bash style=background:#2e3440;color:#d8dee9><code class=language-bash data-lang=bash><span style=color:#88c0d0>$</span><span> python bulk_index_async.py -b 1
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>1/1 </span><span style=color:#81a1c1>[</span><span>00:00&LT00:00,  1.25it/s</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Finished</span><span> running benchmarks
</span><span style=color:#88c0d0>Bulk</span><span> index took 1.5184 seconds
</span><span>
</span><span style=color:#88c0d0>$</span><span> python bulk_index_async.py -b 10
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>10/10 </span><span style=color:#81a1c1>[</span><span>00:09&LT00:00,  1.10it/s</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Finished</span><span> running benchmarks
</span><span style=color:#88c0d0>Bulk</span><span> index took 9.7602 seconds
</span><span>
</span><span style=color:#616e88># Run 1 for 100 batches
</span><span style=color:#88c0d0>$</span><span> python bulk_index_async.py -b 100 --chunksize 5000
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>100/100 </span><span style=color:#81a1c1>[</span><span>01:32&LT00:00,  1.08it/s</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Finished</span><span> running benchmarks
</span><span style=color:#88c0d0>Bulk</span><span> index took 93.1814 seconds
</span><span>
</span><span style=color:#616e88># Run 2 for 100 batches
</span><span style=color:#88c0d0>$</span><span> python bulk_index_async.py -b 100 --chunksize 2000
</span><span style=color:#88c0d0>Finished</span><span> updating database index settings
</span><span style=color:#88c0d0>100</span><span style=color:#81a1c1>%|</span><span style=color:#88c0d0>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#81a1c1>| </span><span style=color:#88c0d0>100/100 </span><span style=color:#81a1c1>[</span><span>01:40&LT00:00,  1.01s/it</span><span style=color:#81a1c1>]
</span><span style=color:#88c0d0>Finished</span><span> running benchmarks
</span><span style=color:#88c0d0>Bulk</span><span> index took 101.4677 seconds
</span></code></pre></div><p>It‚Äôs clear that the async data loader is faster than the sync version for all cases.<h2 id=results-discussion>Results & discussion<a aria-label="Anchor link for: results-discussion" class=zola-anchor href=#results-discussion>#</a></h2><p>The results of the benchmarking are summarized in the table below. The async version is consistently faster than the sync version, with the difference in performance remaining more or less the same as the number of records being loaded increases. The async version is at least <strong>~30%</strong> faster than the sync version for all cases.<figure><img loading=lazy src=meilisearch-sync-vs-async-results.png></figure><p>However, in running the async code for 100 batches of data (~13 million records), the script <a rel="nofollow noreferrer" href=https://github.com/prrao87/db-hub-fastapi/pull/41#issuecomment-1654907416>crashed due to a memory issue</a> with the default <code>CHUNKSIZE</code> of 10k. I suspect this is because the async batch loader eagerly allocates a certain amount of memory for each batch, causing it to run out of buffer space when many batches are sent at once.<p>As a best practice, for very large async data loads, it makes sense to do the following:<ul><li>Run smaller batch sizes (e.g. 2k) ‚Äì this number depends on your data and the memory available on the machine<li>Divide the dataset into smaller chunks, and iterate through these chunks using a synchronous for loop ‚Äì this allows you to enforce the execution of each batch sequentially, while still taking advantage of async batch loading <em>within</em> each batch.</ul><blockquote class="callout note"><div class=icon><svg viewbox="0 0 24 24" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M12 22C6.47715 22 2 17.5228 2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22ZM12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20ZM11 7H13V9H11V7ZM11 11H13V17H11V11Z" fill=currentColor></path></svg></div><div class=content><p><strong>Note</strong><p>It‚Äôs worth noting that the data ingestion is only the first step in the ETL pipeline, which gets data <em>into</em> Meilisearch. Once it‚Äôs ingested, Meilisearch‚Äôs task queue kicks in, and the indexing steps run asynchronously in the background for a few minutes, following which the data can be queried on the front end. The data is <em>eventually</em> available in Meilisearch, just not as soon as it‚Äôs been loaded. Follow Meilisearch best practices to avoid very large indexing times.</div></blockquote><h3 id=search-results-on-the-front-end>Search results on the front end<a aria-label="Anchor link for: search-results-on-the-front-end" class=zola-anchor href=#search-results-on-the-front-end>#</a></h3><p>Meilisearch allows developers to test the load by querying the database via a simple front end. A demo of the search is shown below, which returns the most relevant results for the query <code>2010 cabernet sauvignon</code>. Note how the search is able to handle typos, which is one of the strengths of Meilisearch‚Äôs indexing scheme. The results are returned almost as fast as terms are typed in, which is the best part!<figure><img loading=lazy src=meilisearch.gif></figure><h2 id=conclusions>Conclusions<a aria-label="Anchor link for: conclusions" class=zola-anchor href=#conclusions>#</a></h2><p>In this post, we‚Äôve seen how to use Meilisearch to build a fast, full-text search engine to search through a sample dataset of wine reviews. We‚Äôve also seen how to use the Meilisearch Python client (both sync and async) to load data into the database. In general, the async loader will be a fair bit faster than the sync loader, but it‚Äôs worth testing them both out and tuning the batch sizes to get the best performance with the available memory in your situation, on your specific data.<h3 id=when-is-meilisearch-a-great-fit>When is Meilisearch a great fit?<a aria-label="Anchor link for: when-is-meilisearch-a-great-fit" class=zola-anchor href=#when-is-meilisearch-a-great-fit>#</a></h3><p>Meilisearch is an excellent choice for building search-as-you-type interfaces on end user-facing websites when keyword search is the primary search mechanism. In fact, a real-world case study showed that switching to Meilisearch from ElasticSearch improved the search experience on <a rel="nofollow noreferrer" href=https://bookshop.org/>bookshop.org</a>, increasing overall conversion by <strong>43%</strong><sup class=footnote-reference><a href=#5>6</a></sup>.<p>Another area where Meilisearch shines is in its ability to handle typos and misspellings in search queries. This is because Meilisearch implements a host of algorithms to match search terms to the closest terms in the index. This is a very useful feature for search-as-you-type interfaces, where users are highly likely to make spelling mistakes, and the aim is to have relevant results for terms that are off by one or two characters.<p>Lastly, <em>faceted</em> search - where you need to refine search results by broad categories - is also a great use case for Meilisearch. This greatly improves user experience by allowing the user to select filtering by facets, such as brand, size, or rating range as per the e-commerce example image below.<figure><img alt="Image source: Faceted search in <a href='https://blog.meilisearch.com/postgres-full-text-search-limitations/'>Meilisearch blog</a>" loading=lazy src=meilisearch-facets.png><figcaption>Image source: Faceted search in <a href=https://blog.meilisearch.com/postgres-full-text-search-limitations/>Meilisearch blog</a></figcaption></figure><h3 id=limitations-of-meilisearch>Limitations of Meilisearch<a aria-label="Anchor link for: limitations-of-meilisearch" class=zola-anchor href=#limitations-of-meilisearch>#</a></h3><p>Because Meilisearch was designed from the ground up to be a near-instant search data store, it does not have great support for aggregations or analytics, which are features we might be used to from other NoSQL databases like ElasticSearch and MongoDB. More info on this is provided in an excellent blog post<sup class=footnote-reference><a href=#4>5</a></sup> by the Meilisearch creators themselves.<p>As they themselves state<sup class=footnote-reference><a href=#4>5</a></sup>:<blockquote><p>Meilisearch is not made to search through billions of large text files or parse complex queries. This kind of searching power would require a higher degree of complexity and lead to slower search experiences, which runs against our instant search philosophy. For those purposes, look no further than Elasticsearch; it‚Äôs an excellent solution for companies with the necessary resources, whether that be the financial means to hire consultants or the time and money required to implement it themselves.</blockquote><p>In summary, if your goal is to run analytics on your unstructured data, or more complex queries than string-based information retrieval, such as aggregation queries, then, maybe Meilisearch isn‚Äôt the best choice ‚Äì stick to more established alternatives like MongoDB or ElasticSearch that were designed to store humongous amounts of data.<h2 id=code-acknowledgements>Code & acknowledgements<a aria-label="Anchor link for: code-acknowledgements" class=zola-anchor href=#code-acknowledgements>#</a></h2><p>As always, the code as well as the dataset used in this post is available on <a rel="nofollow noreferrer" href=https://github.com/prrao87/db-hub-fastapi/tree/main/dbs/meilisearch/scripts>GitHub</a>.<p>Many, many thanks to <a rel="nofollow noreferrer" href=https://paulsanders.dev/>Paul Sanders</a>, author of the Meilisearch async Python client<sup class=footnote-reference><a href=#1>1</a></sup>, from whom I learned a lot about combining multiprocessing and async workflows in Python<sup class=footnote-reference><a href=#6>7</a></sup> and speeding up and debugging async workflows<sup class=footnote-reference><a href=#7>8</a></sup>. I highly recommend trying out his Python SDK for your upcoming work with Meilisearch!<hr><div class=footnote-definition id=1><sup class=footnote-definition-label>1</sup><p>Meilisearch async Python client, <a rel="nofollow noreferrer" href=https://github.com/sanders41/meilisearch-python-sdk>Paul Sanders</a></div><div class=footnote-definition id=2><sup class=footnote-definition-label>2</sup><p>Asyncio race conditions, <a rel="nofollow noreferrer" href=https://superfastpython.com/asyncio-race-conditions/>Jason Brownlee</a></div><div class=footnote-definition id=3><sup class=footnote-definition-label>3</sup><p>Are you indexing the smart way? Meilisearch blog, <a rel="nofollow noreferrer" href=https://blog.meilisearch.com/best-practices-for-faster-indexing/>Carolina Ferreira</a></div><div class=footnote-definition id=4><sup class=footnote-definition-label>5</sup><p>Meilisearch vs Elasticsearch, Meilisearch blog, <a rel="nofollow noreferrer" href=https://blog.meilisearch.com/why-should-you-use-meilisearch-over-elasticsearch/>Carolina Ferreira</a></div><div class=footnote-definition id=5><sup class=footnote-definition-label>6</sup><p>Bookshop.org increases search-based purchases by 43% with Meilisearch, <a rel="nofollow noreferrer" href=https://blog.meilisearch.com/bookshop-increases-search-based-purchases/>Maya Shin</a></div><div class=footnote-definition id=6><sup class=footnote-definition-label>7</sup><p>Combining Python multi-processor with async, <a rel="nofollow noreferrer" href=https://github.com/prrao87/db-hub-fastapi/pull/15>GitHub PR #15</a></div><div class=footnote-definition id=7><sup class=footnote-definition-label>8</sup><p>Understanding the memory implications of batch loading with async, <a rel="nofollow noreferrer" href=https://github.com/prrao87/db-hub-fastapi/pull/41>PR #41</a></div><div class=footnote-definition id=8><sup class=footnote-definition-label>4</sup><p>Tasks and async operations, <a rel="nofollow noreferrer" href=https://www.meilisearch.com/docs/learn/async/asynchronous_operations>Meilisearch docs</a></div></article><div class=giscus></div><script async crossorigin data-category=General data-category-id=DIC_kwDOKyWhTs4CbUSt data-emit-metadata=0 data-input-position=bottom data-lang=en data-loading=lazy data-mapping=pathname data-reactions-enabled=1 data-repo=thedataquarry/thedataquarry.github.io data-repo-id=R_kgDOKyWhTg data-strict=0 data-theme=preferred_color_scheme src=https://giscus.app/client.js></script></div><footer><div class=copyright><p>¬© 2024 Prashanth Rao</div><div class=credits>Powered by <a rel="noreferrer noopener" href=https://www.getzola.org target=_blank>zola</a> and <a rel="noreferrer noopener" href=https://github.com/isunjn/serene target=_blank>serene</a></div></footer></main></div><script src=/js/lightense.min.js></script><script src=/js/main.js></script>